{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nsdf](https://www.sci.utah.edu/~pascucci/public/NSDF-large.png)  \n",
    "[National Science Data Fabric](https://nationalsciencedatafabric.org/) \n",
    "\n",
    "# Create Streamable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sys.path.append(\"C:/projects/OpenVisus/build/RelWithDebInfo\")\n",
    "#sys.path.append(\"C:/projects/openvisuspy/src\")\n",
    "\n",
    "import OpenVisus as ov\n",
    "import openvisuspy as ovy\n",
    "\n",
    "def ShowImage(slice):\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(slice) \n",
    "    plt.colorbar(im)\n",
    "\n",
    "os.environ[\"VISUS_DISABLE_WRITE_LOCK\"]=\"1\"\n",
    "\n",
    "print(\"OpenVisus imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Nexus file\n",
    "\n",
    "Note **it's a 5 GB** file so it will take a lot to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_filename = '/mnt/data/chess/assets/reconstructed_data.nxs'\n",
    "from openvisuspy import DownloadObject\n",
    "DownloadObject(\"s3://utah/assets/ff1_000231.h5\",h5_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read from original HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to reach the binary data inside the HDF5\n",
    "expression ='/shanks-3731-a/data/reconstructed_data'\n",
    "\n",
    "# xarray needs to read one level-up (i.e. at group level)\n",
    "group,fieldname  = expression.rsplit(\"/\",maxsplit=1) \n",
    "\n",
    "ds = xr.open_dataset(h5_filename, group=group)\n",
    "field=ds[fieldname]\n",
    "data=field[...].values\n",
    "print(\"Got data\",\"type\",type(data),\"shape\",data.shape,\"dtype\",data.dtype,\"min\",np.min(data),\"max\",np.max(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the HDF5 structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install --quiet h5glance\n",
    "from h5glance import H5Glance\n",
    "H5Glance(h5_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=100\n",
    "slice=data[Z,:,:]\n",
    "ShowImage(slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create streamable version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvisuspy.create_streamable import Streamable\n",
    "\n",
    "# create streamable local version, where each 3d field will be an OpenVisus dataset\n",
    "local_url = f\"./remove-me/streamable/reconstructed_data/visus.nxs\"\n",
    "\n",
    "Streamable.Create(\n",
    "    \n",
    "    # original hdf5\n",
    "    h5_filename, \n",
    "\n",
    "    # local streamable version\n",
    "    local_url, \n",
    "    \n",
    "    # arco\n",
    "    arco=\"2mb\", \n",
    "\n",
    "    # copmpression\n",
    "    compression=\"zip\", \n",
    "\n",
    "    # I need to predeclare what will be the options to open/read the binary data\n",
    "    # I can choose later (by using `prefer` argument) which one to use \n",
    "    # {name} is the internal HDF5 expression to reach the data\n",
    "    idx_urls={\n",
    "    \n",
    "    \t# alias to a dic item that will be used for the `public`\n",
    "    \t\"default\": \"remote\",\n",
    "    \n",
    "    \t# this is needed to generate internal local dtaset\n",
    "        # ./remove-me/streamable/reconstructed_data/visus/{name}/visus.idx\n",
    "    \t\"local\": \"./remove-me/streamable/reconstructed_data/visus/{name}/visus.idx\",\n",
    "    \n",
    "    \t# network s3 storage\n",
    "        # e.g https://maritime.sealstorage.io/api/v0/s3/utah/streamable/hdf5/reconstructed_data/visus/{name}/visus.idx\n",
    "    \t\"remote\": \"https://maritime.sealstorage.io/api/v0/s3/utah/streamable/hdf5/reconstructed_data/visus/{name}/visus.idx?cached=arco&access_key=any&secret_key=any&endpoint_url=https://maritime.sealstorage.io/api/v0/s3&cached=arco\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show streamable version has exactly the same metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to see any extra  metadata that H5Glance does not show\n",
    "Streamable.Print(local_url)\n",
    "# H5Glance(local_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read  from local streamable (i.e. OpenVisus reads binary data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvisuspy.xarray_backend import OpenVisusBackendEntrypoint\n",
    "ds = xr.open_dataset(\n",
    "    local_url, \n",
    "    group=group, \n",
    "\n",
    "    # this is telling xarray to open binary data using OpenVisus\n",
    "    engine=OpenVisusBackendEntrypoint, \n",
    "\n",
    "    # since I know I have data locally, I will open preferring local storage\n",
    "    prefer=\"local\"\n",
    ")\n",
    "\n",
    "field=ds[fieldname]\n",
    "timestep,res=0,27\n",
    "data=field[timestep,...,res].values\n",
    "print(\"Got data\",\"type\",type(data),\"shape\",data.shape,\"dtype\",data.dtype,\"min\",np.min(data),\"max\",np.max(data))\n",
    "\n",
    "Z=100\n",
    "slice=data[Z,...]\n",
    "ShowImage(slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  (OPTIONAL SINCE ALREADY UPLOADED) Upload data to S3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_upload=False\n",
    "if do_upload:\n",
    "  os.system(f'aws s3 sync --no-verify-ssl --endpoint-url \"https://maritime.sealstorage.io/api/v0/s3\" --profile sealstorage --size-only ./remove-me/streamable/reconstructed_data/ s3://utah/streamable/hdf5/reconstructed_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data from S3\n",
    "\n",
    "NOTE: the first time will be slow, the second will be a lot faster thanks to the cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I already have the file locally, but in case you need to get it\n",
    "# NOTE directly opening the stream using f3fs is causing some problems with `xr.open_dataset` so I am saving the file locally first\n",
    "\n",
    "from openvisuspy import DownloadObject\n",
    "DownloadObject(\"s3://utah/streamable/hdf5/reconstructed_data/visus.nxs\",local_url)\n",
    "\n",
    "# cache will be filled here...\n",
    "if not \"VISUS_CACHE\" in os.environ:\n",
    "    os.environ[\"VISUS_CACHE\"]=\"./remove-me/streamable/reconstructed_data/visus-cache\"\n",
    "\n",
    "ds=xr.open_dataset(\n",
    "    local_url, \n",
    "    group=group, \n",
    "    engine=OpenVisusBackendEntrypoint, \n",
    "    # NOTE: this time I have the data remotely (and will cache it too!)\n",
    "    prefer=\"remote\"\n",
    ")\n",
    "\n",
    "field=ds[fieldname]\n",
    "timestep,res=0,27\n",
    "data=field[timestep,...,res].values\n",
    "print(\"Got data\",\"type\",type(data),\"shape\",data.shape,\"dtype\",data.dtype,\"min\",np.min(data),\"max\",np.max(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show streamable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=100\n",
    "slice=data[Z,...]\n",
    "ShowImage(slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
