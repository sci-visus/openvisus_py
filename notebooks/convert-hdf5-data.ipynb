{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nsdf](https://www.sci.utah.edu/~pascucci/public/NSDF-large.png)  \n",
    "[National Science Data Fabric](https://nationalsciencedatafabric.org/) \n",
    "\n",
    "# Converting HDF5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ,sys, time, logging,shutil\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import boto3\n",
    "import h5py\n",
    "from pprint import pprint\n",
    "\n",
    "#sys.path.append(\"C:/projects/OpenVisus/build/RelWithDebInfo\")\n",
    "#sys.path.append(\"C:/projects/openvisuspy/src\")\n",
    "\n",
    "import OpenVisus as ov\n",
    "import openvisuspy\n",
    "os.environ[\"VISUS_DISABLE_WRITE_LOCK\"]=\"1\"\n",
    "logger= logging.getLogger(\"OpenVisus\")\n",
    "\n",
    "# uncomment for debugging\n",
    "# ov.SetupLogger(logger, stream=True)\n",
    "\n",
    "from openvisuspy.utils import DownloadObject\n",
    "\n",
    "print(\"OpenVisus imported\")\n",
    "\n",
    "# /////////////////////////////////////////////////////////////////////////////////\n",
    "def Traverse(cur):\n",
    "    \"\"\"\n",
    "    Utility to show the internal of an HDF5 file\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(cur,h5py.Dataset):\n",
    "        return {\n",
    "            '__type':type(cur),\n",
    "            'shape':cur.shape,\n",
    "            'dtype':cur.dtype,\n",
    "            'size':cur.size,\n",
    "            'ndim':cur.ndim,\n",
    "            'nbytes':cur.nbytes,\n",
    "        }\n",
    "    else:\n",
    "        return {key: Traverse(cur[key])for key in cur.keys()}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need an HDF5 file to convert.\n",
    "\n",
    "I can download from the cloud but NOTE: **it's 33GB file**, it will take a lot to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_filename='/mnt/data/chess/assets/ff1_000231.h5'\n",
    "DownloadObject(\"s3://utah/assets/ff1_000231.h5\", hdf5_filename)\n",
    "f = h5py.File(hdf5_filename, 'r') \n",
    "pprint(Traverse(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read binary data\n",
    "\n",
    "A single dataset is 33GB. \n",
    "\n",
    "**Better to now load all in memory**; here I am reading only a little portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# ///////////////////////////////////////////////////////////////\n",
    "def ShowImage(img, histogram=True):\n",
    "\tprint(\"dtype\",img.dtype,\"shape\",img.shape,\"m\",np.min(img),\"M\",np.max(img))\n",
    "\tfig = plt.figure()\n",
    "\tfig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "\tax = fig.add_subplot(1, 2, 1) # nrows, ncols, index\n",
    "\timgplot = plt.imshow(img)\n",
    "\n",
    "\tplt.colorbar(orientation='horizontal')\n",
    "\tif histogram:\n",
    "\t\tax = fig.add_subplot(1, 2, 2)\n",
    "\t\thistogram, bin_edges = np.histogram(img, bins=256, range=(np.min(img), np.max(img)))\n",
    "\t\tplt.title(\"Histogram\")\n",
    "\t\tplt.xlabel(\"value\")\n",
    "\t\tplt.ylabel(\"pixel count\")\n",
    "\t\tplt.xlim([np.min(img), np.max(img)])\n",
    "\t\tplt.plot(bin_edges[0:-1], histogram)\n",
    "\n",
    "\n",
    "images=f[\"imageseries\"][\"images\"]\n",
    "D,H,W=images.shape\n",
    "print(f\"Images dtype={images.dtype} shape={images.shape} \")\n",
    "\n",
    "Z=300\n",
    "img=images[Z,:,:]\n",
    "print(np.min(slice),np.max(slice))\n",
    "\n",
    "from skimage import io,exposure\n",
    "ShowImage(exposure.equalize_hist(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create OpenVisus file\n",
    "\n",
    "NOTE **Converting only a litte portion of data (don't want to have 33GB in memory)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: creating the dataset in a temporary local directory , that is safe to remove\n",
    "idx_filename=\"./remove-me/hdf5-example/visus.idx\"\n",
    "\n",
    "reduced_depth=D//3\n",
    "print(\"Reduced depth to\",reduced_depth)\n",
    "\n",
    "import os,sys,shutil\n",
    "assert(\"remove-me\" in idx_filename)\n",
    "shutil.rmtree(os.path.dirname(idx_filename), ignore_errors=True)\n",
    "\n",
    "data=images[0:reduced_depth,:,:]\n",
    "\n",
    "fields=[ov.Field(\"data\",str(data.dtype),\"row_major\")]\n",
    "db=ov.CreateIdx(\n",
    "\turl=idx_filename,\n",
    "\tdims=[W,H,reduced_depth],\n",
    "\tfields=fields,\n",
    "    # NOTE: we are first creating the dataset with no-compression\n",
    "\tcompression=\"raw\")\n",
    "\n",
    "print(db.getDatasetBody().toString())\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write  data to OpenVisus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "db.write(data)\n",
    "print(f\"db.write done in {time.time() - t1} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (OPTIONAL) Compress using zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in production is better to compress the dataset\n",
    "do_compress=False\n",
    "if do_compress:\n",
    "    t1 = time.time()\n",
    "    db.compressDataset([\"zip\"])\n",
    "    print(f\"db.compressDataset done in {time.time()-t1} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show OpenVisus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "img=db.read(x=[0,W],y=[0,H],z=[Z,Z+1], num_refinements=1)[0,:,:]\n",
    "print(img.dtype,img.shape)\n",
    "ShowImage(exposure.equalize_hist(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show coarse to fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "for img in db.read(x=[0,W],y=[0,H],z=[Z,Z+1], num_refinements=3):\n",
    "\tShowImage(exposure.equalize_hist(img[0,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
